{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf3673c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_PATH = '/media/ybahat/data/Datasets/Diversity'\n",
    "DATASET_GROUP = 'webcams' #'faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf9e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from interactivecrop.interactivecrop import main as crop\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a90eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using youtube-dl:\n",
    "# VIDEO_URL = 'https://www.youtube.com/watch?v=I2uGOQTY9uk&t=1s'\n",
    "VIDEO_URL = 'https://www.youtube.com/watch?v=HpZAez2oYsA'\n",
    "\n",
    "import youtube_dl\n",
    "ydl = youtube_dl.YoutubeDL({'outtmpl': '%(id)s.%(ext)s'})\n",
    "\n",
    "with ydl:\n",
    "    result = ydl.extract_info(\n",
    "        VIDEO_URL,\n",
    "        download=True # We just want to extract the info\n",
    "    )\n",
    "\n",
    "downloaded_file = '%s.%s'%(result['id'],result['ext'])\n",
    "\n",
    "# An alternative downloading method, from terminal:\n",
    "# streamlink --hls-live-edge 99999 --hls-segment-threads 5 --hls-duration 1:00:00 -o \"video.mp4\" https://www.youtube.com/watch?v=RQA5RcIZlAM best\n",
    "\n",
    "# Alternatively, download by recording network streaming using VLC recorder. See instructions in this link:\n",
    "# https://confluence.bethel.edu/display/ITSKB/Recording+a+Network+Stream+with+VLC+Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66bd3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not using youtube-dl:\n",
    "downloaded_file = '/media/ybahat/data/Datasets/Diversity/webcams/video.mp4'\n",
    "result = {'title':'VeneziaBeach'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eabc2316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137dbf0474db4cc3b4b3198328286787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridBox(children=(Dropdown(description='Img Name:', layout=Layout(grid_area='im_selector', width='100%'), optiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FRAME_NUM_4_CROPPING = 1100\n",
    "\n",
    "vidcap = cv2.VideoCapture(downloaded_file)\n",
    "vidcap.set(cv2.CAP_PROP_POS_FRAMES,FRAME_NUM_4_CROPPING)\n",
    "success,image = vidcap.read()\n",
    "# cropped_shape = crop([image[...,[2,1,0]]],['temp'],optimize=False)\n",
    "crop([image[...,[2,1,0]]],optimize=False)\n",
    "# image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a15b9276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 265, 1920, 784)\n"
     ]
    }
   ],
   "source": [
    "cropping_shape = (0,265, 1920,783)\n",
    "temp_shape = list(cropping_shape)\n",
    "temp_shape[2] = int(np.ceil(cropping_shape[2]/16)*16)\n",
    "temp_shape[3] = int(np.ceil(cropping_shape[3]/16)*16)\n",
    "temp_shape[0] += (cropping_shape[2]-temp_shape[2])//2\n",
    "# temp_shape[1] -= (cropping_shape[3]-temp_shape[3])//2\n",
    "cropping_shape = tuple(temp_shape)\n",
    "print(cropping_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44386656",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP_SCALE_FACTOR = 2\n",
    "\n",
    "output_folder = os.path.join(DATABASE_PATH,DATASET_GROUP,result['title'])\n",
    "os.mkdir(output_folder)\n",
    "output_folder = os.path.join(output_folder,'raw_frames' if CLEANUP_SCALE_FACTOR==1 else 'clean_frames')\n",
    "os.mkdir(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf29803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 300001 frames\n"
     ]
    }
   ],
   "source": [
    "vidcap.set(cv2.CAP_PROP_POS_FRAMES,0)\n",
    "success,image = vidcap.read()\n",
    "count = 1\n",
    "while success:\n",
    "    if count>300000:\n",
    "        break\n",
    "    image = image[cropping_shape[1]:cropping_shape[1]+cropping_shape[3],cropping_shape[0]:cropping_shape[0]+cropping_shape[2],...]\n",
    "    if CLEANUP_SCALE_FACTOR>1:\n",
    "        image = cv2.resize(image,dsize=(cropping_shape[2]//CLEANUP_SCALE_FACTOR,cropping_shape[3]//CLEANUP_SCALE_FACTOR),interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(os.path.join(output_folder,\"frame%d.png\" % count),image)\n",
    "    count += 1\n",
    "    success,image = vidcap.read()\n",
    "\n",
    "\n",
    "print('Saved %d frames'%(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8248f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(downloaded_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
